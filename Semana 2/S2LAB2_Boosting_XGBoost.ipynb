{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción e implementación de modelos basados en Boosting\n",
    "En este notebook aprenderá a construir e implementar modelos de Adaboost, Gradient Boosting y XGBoost. El primer modelo lo desarrollará de forma manual y usando la librería especializada sklearn, mientras que los otros dos los desarrollará solamente usando la librería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales:\n",
    "\n",
    "Los modelos que construirá por medio de este notebook deberán predecir si un usuario deja o no de usar los servicios de una compañía (churn) teniendo en cuenta diferentes variables. Para conocer más detalles de la base de 'churn' puede ingresar al siguiente vínculo: http://srepho.github.io/Churn/Churn\n",
    "\n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar base de datos y librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carga de datos de archivos .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>AZ</td>\n",
       "      <td>192</td>\n",
       "      <td>415</td>\n",
       "      <td>414-4276</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>WV</td>\n",
       "      <td>68</td>\n",
       "      <td>415</td>\n",
       "      <td>370-3271</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>RI</td>\n",
       "      <td>28</td>\n",
       "      <td>510</td>\n",
       "      <td>328-8230</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>CT</td>\n",
       "      <td>184</td>\n",
       "      <td>510</td>\n",
       "      <td>364-6381</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>TN</td>\n",
       "      <td>74</td>\n",
       "      <td>415</td>\n",
       "      <td>400-4344</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0       KS             128        415  382-4657         no        yes   \n",
       "1       OH             107        415  371-7191         no        yes   \n",
       "2       NJ             137        415  358-1921         no         no   \n",
       "3       OH              84        408  375-9999        yes         no   \n",
       "4       OK              75        415  330-6626        yes         no   \n",
       "...    ...             ...        ...       ...        ...        ...   \n",
       "3328    AZ             192        415  414-4276         no        yes   \n",
       "3329    WV              68        415  370-3271         no         no   \n",
       "3330    RI              28        510  328-8230         no         no   \n",
       "3331    CT             184        510  364-6381        yes         no   \n",
       "3332    TN              74        415  400-4344         no        yes   \n",
       "\n",
       "      VMail Message  Day Mins  Day Calls  Day Charge  ...  Eve Calls  \\\n",
       "0                25     265.1        110       45.07  ...         99   \n",
       "1                26     161.6        123       27.47  ...        103   \n",
       "2                 0     243.4        114       41.38  ...        110   \n",
       "3                 0     299.4         71       50.90  ...         88   \n",
       "4                 0     166.7        113       28.34  ...        122   \n",
       "...             ...       ...        ...         ...  ...        ...   \n",
       "3328             36     156.2         77       26.55  ...        126   \n",
       "3329              0     231.1         57       39.29  ...         55   \n",
       "3330              0     180.8        109       30.74  ...         58   \n",
       "3331              0     213.8        105       36.35  ...         84   \n",
       "3332             25     234.4        113       39.85  ...         82   \n",
       "\n",
       "      Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  \\\n",
       "0          16.78       244.7           91         11.01       10.0   \n",
       "1          16.62       254.4          103         11.45       13.7   \n",
       "2          10.30       162.6          104          7.32       12.2   \n",
       "3           5.26       196.9           89          8.86        6.6   \n",
       "4          12.61       186.9          121          8.41       10.1   \n",
       "...          ...         ...          ...           ...        ...   \n",
       "3328       18.32       279.1           83         12.56        9.9   \n",
       "3329       13.04       191.3          123          8.61        9.6   \n",
       "3330       24.55       191.9           91          8.64       14.1   \n",
       "3331       13.57       139.2          137          6.26        5.0   \n",
       "3332       22.60       241.4           77         10.86       13.7   \n",
       "\n",
       "      Intl Calls  Intl Charge  CustServ Calls  Churn?  \n",
       "0              3         2.70               1  False.  \n",
       "1              3         3.70               1  False.  \n",
       "2              5         3.29               0  False.  \n",
       "3              7         1.78               2  False.  \n",
       "4              3         2.73               3  False.  \n",
       "...          ...          ...             ...     ...  \n",
       "3328           6         2.67               2  False.  \n",
       "3329           4         2.59               3  False.  \n",
       "3330           6         3.81               2  False.  \n",
       "3331          10         1.35               2  False.  \n",
       "3332           4         3.70               0  False.  \n",
       "\n",
       "[3333 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables numéricas (X)\n",
    "X = data.iloc[:, [1,2,6,7,8,9,10]].astype(np.float)\n",
    "# Tranformación de variables booleanas a floats\n",
    "X = X.join((data.iloc[:, [4,5]] == 'no').astype(np.float))\n",
    "\n",
    "# Definición variable de interés binaria (y)\n",
    "y = (data.iloc[:, -1] == 'True.').astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2233"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=40)\n",
    "n_samples = X_train.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9\n",
       "2953  0.000448  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "617   0.000448  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "26    0.000448  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "853   0.000448  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "2510  0.000448  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de la cantidad de árboles de decisión del modelo\n",
    "n_estimators = 10\n",
    "\n",
    "# Definición de DataFrame para guardar pesos de las observaciones en cada árbol de decisión\n",
    "weights = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))\n",
    "\n",
    "# Asignación los mismos pesos para todas las observaciones en el árbol 0\n",
    "t = 0\n",
    "weights[t] = 1 / n_samples\n",
    "\n",
    "# Visualización de DataFrame de pesos\n",
    "weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Definición y entrenamiento (fit) del primer árbol de decisión (DecisionTreeClassifier)\n",
    "trees = []\n",
    "trees.append(DecisionTreeClassifier(max_depth=1))\n",
    "trees[t].fit(X_train, y_train, sample_weight=weights[t].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24114832535885167"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimación del error del primer árbol de decisión\n",
    "y_pred_ = trees[t].predict(X_train)\n",
    "error = []\n",
    "#error.append(1 - metrics.balanced_accuracy_score(y_pred_, y_train, weights[t].values))# Linea de comando original, noc corrio con el 3 parametro\n",
    "error.append(1 - metrics.balanced_accuracy_score(y_pred_, y_train))\n",
    "error[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5731970670617124"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo del factor alpha del primer árbol de decisión\n",
    "alpha = []\n",
    "alpha.append(np.log((1 - error[t]) / error[t])/2)\n",
    "alpha[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualización de los pesos a considerar en el segundo árbol (t+1)\n",
    "weights[t + 1] = weights[t]\n",
    "filter_ = y_pred_ != y_train\n",
    "\n",
    "weights.loc[filter_, t + 1] = weights.loc[filter_, t] * np.exp(alpha[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los pesos\n",
    "weights[t + 1] = weights[t + 1] / weights[t + 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.004453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "2953  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "617   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "26    0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "853   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "2510  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "2872  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "2469  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "264   0.000448  0.000406  0.000376  0.000279  0.000329  0.000284  0.000345   \n",
       "1132  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "585   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "1146  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "874   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "3221  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "609   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "3135  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "971   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "1991  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "1218  0.000448  0.000406  0.000376  0.000279  0.000329  0.000284  0.000345   \n",
       "2550  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "1532  0.000448  0.000720  0.000924  0.001623  0.001911  0.002288  0.002775   \n",
       "\n",
       "            7         8         9         10  \n",
       "2953  0.000100  0.000049  0.000056  0.000026  \n",
       "617   0.000100  0.000049  0.000056  0.000026  \n",
       "26    0.000100  0.000049  0.000056  0.000026  \n",
       "853   0.000100  0.000049  0.000056  0.000026  \n",
       "2510  0.000100  0.000049  0.000056  0.000026  \n",
       "2872  0.000100  0.000049  0.000056  0.000026  \n",
       "2469  0.000100  0.000049  0.000056  0.000026  \n",
       "264   0.000192  0.000093  0.000107  0.000049  \n",
       "1132  0.000100  0.000049  0.000056  0.000026  \n",
       "585   0.000100  0.000049  0.000056  0.000026  \n",
       "1146  0.000100  0.000049  0.000056  0.000026  \n",
       "874   0.000100  0.000049  0.000056  0.000026  \n",
       "3221  0.000100  0.000049  0.000056  0.000026  \n",
       "609   0.000100  0.000049  0.000056  0.000026  \n",
       "3135  0.000100  0.000049  0.000056  0.000026  \n",
       "971   0.000100  0.000049  0.000056  0.000026  \n",
       "1991  0.000100  0.000049  0.000056  0.000026  \n",
       "1218  0.000192  0.000093  0.000107  0.000049  \n",
       "2550  0.000100  0.000049  0.000056  0.000026  \n",
       "1532  0.003644  0.004200  0.004124  0.004453  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización de DataFrame de pesos\n",
    "weights.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de loop que itera sobre todos los árboles definidos realizando los mismos cáculos presentados anteriormente\n",
    "for t in range(1, n_estimators):\n",
    "    # Definición y entrenamiento (fit) del árbol t\n",
    "    trees.append(DecisionTreeClassifier(max_depth=1))\n",
    "    trees[t].fit(X_train, y_train, sample_weight=weights[t].values)\n",
    "    y_pred_ = trees[t].predict(X_train)\n",
    "    # Estimación del error del árbol t\n",
    "    #error.append(1 - metrics.balanced_accuracy_score(y_pred_, y_train, weights[t].values))# Linea de comando original, noc corrio con el 3 parametro\n",
    "    error.append(1 - metrics.balanced_accuracy_score(y_pred_, y_train))\n",
    "    # Cálculo del factor alpha para el árbol t\n",
    "    alpha.append(np.log((1 - error[t]) / error[t]) / 2)\n",
    "    # Actualización de pesos para el árbol t+2\n",
    "    weights[t + 1] = weights[t]\n",
    "    filter_ = y_pred_ != y_train\n",
    "    weights.loc[filter_, t + 1] = weights.loc[filter_, t] * np.exp(alpha[t])\n",
    "    weights[t + 1] = weights[t + 1] / weights[t + 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24114832535885167,\n",
       " 0.3426559974503153,\n",
       " 0.15181370353784152,\n",
       " 0.37037293415246175,\n",
       " 0.3426559974503153,\n",
       " 0.31821584921188295,\n",
       " 0.8481862964621585,\n",
       " 0.8481862964621585,\n",
       " 0.4236486486486486,\n",
       " 0.8481862964621585]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización de los errores de cada árbol\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "2953  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "617   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "26    0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "853   0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "2510  0.000448  0.000406  0.000376  0.000279  0.000252  0.000218  0.000181   \n",
       "\n",
       "          7         8         9         10  \n",
       "2953  0.0001  0.000049  0.000056  0.000026  \n",
       "617   0.0001  0.000049  0.000056  0.000026  \n",
       "26    0.0001  0.000049  0.000056  0.000026  \n",
       "853   0.0001  0.000049  0.000056  0.000026  \n",
       "2510  0.0001  0.000049  0.000056  0.000026  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización de DataFrame de pesos\n",
    "weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo se usan modelos con error menor a 0.5\n",
    "new_n_estimators = np.sum([x<0.5 for x in error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prección sobre la muestra de test\n",
    "y_pred_all = np.zeros((X_test.shape[0], new_n_estimators))\n",
    "for t in range(new_n_estimators):\n",
    "    y_pred_all[:, t] = trees[t].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de la predicción final al poderar las predicciones por el factor aplha\n",
    "y_pred = (np.sum(y_pred_all * alpha[:new_n_estimators], axis=1) >= 1).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06622516556291391, 0.8718181818181818)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión del desempeño modelo\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33116883116883117, 0.8127272727272727)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de un sólo árbol de decisón para compara el desempeño\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación y definición de modelo AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36771300448430494, 0.8718181818181818)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento (fit) y desempeño del modelo AdaBoostClassifier\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación y definición de modelo GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4644549763033175, 0.8972727272727272)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento (fit) y desempeño del modelo GradientBoostingClassifier\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost usando sklearn\n",
    "Instalar la librería xgboost usando el comando: pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación y definición de modelo XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4298245614035088, 0.8818181818181818)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento (fit) y desempeño del modelo XGBClassifier\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
